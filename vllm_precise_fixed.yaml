apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "7"
    meta.helm.sh/release-name: ms-kv-events
    meta.helm.sh/release-namespace: dpikus-ns
  creationTimestamp: "2025-10-15T13:47:04Z"
  generation: 78
  labels:
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: v0.2.0
    helm.sh/chart: llm-d-modelservice-v0.2.11
  name: ms-kv-events-llm-d-modelservice-decode1
  namespace: dpikus-ns
  uid: 3ab0d40a-c34d-4bdd-a78b-09854cf59408
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      llm-d.ai/inferenceServing: "true"
      llm-d.ai/model: ms-kv-events-llm-d-modelservice
      llm-d.ai/role: decode
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        llm-d.ai/inferenceServing: "true"
        llm-d.ai/model: ms-kv-events-llm-d-modelservice
        llm-d.ai/role: decode
    spec:
      containers:
      - args:
        - |
          vllm serve Qwen/Qwen3-32B \
          --host 0.0.0.0 \
          --port 8200 \
          --block-size 64 \
          --prefix-caching-hash-algo sha256_cbor \
          --enforce-eager \
          --gpu-memory-utilization 0.95 \
          --tensor-parallel-size 2 \
          --kv-events-config "{\"enable_kv_cache_events\":true,\"publisher\":\"zmq\",\"endpoint\":\"tcp://gaie-${GAIE_RELEASE_NAME_POSTFIX}-epp.${NAMESPACE}.svc.cluster.local:5557\",\"topic\":\"kv@${POD_IP}@Qwen/Qwen3-32B\"}"
        command:
        - /bin/sh
        - -c
        env:
        - name: HF_HOME
          value: /model-cache
        - name: GAIE_RELEASE_NAME_POSTFIX
          value: kv-events
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: PYTHONHASHSEED
          value: "42"
        - name: POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: UCX_TLS
          value: cuda_ipc,cuda_copy,tcp
        - name: VLLM_NIXL_SIDE_CHANNEL_HOST
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: VLLM_NIXL_SIDE_CHANNEL_PORT
          value: "5557"
        - name: VLLM_LOGGING_LEVEL
          value: DEBUG
        - name: VLLM_ALLOW_LONG_MAX_MODEL_LEN
          value: "1"
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              key: HF_TOKEN
              name: llm-d-hf-token
        image: ghcr.io/llm-d/llm-d-cuda:v0.3.0
        imagePullPolicy: IfNotPresent
        name: vllm
        ports:
        - containerPort: 5557
          protocol: TCP
        - containerPort: 8200
          name: metrics
          protocol: TCP
        resources:
          limits:
            nvidia.com/gpu: "2"
          requests:
            cpu: "16"
            memory: 100Gi
            nvidia.com/gpu: "2"
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /model-cache
          name: model-cache
        - mountPath: /.config
          name: metrics-volume
        - mountPath: /.cache
          name: torch-compile-cache
        - mountPath: /dev/shm
          name: shm
      dnsPolicy: ClusterFirst
      initContainers:
      - args:
        - --port=8000
        - --vllm-port=8200
        - --connector=nixlv2
        - -v=1
        - --secure-proxy=false
        image: ghcr.io/llm-d/llm-d-routing-sidecar:v0.3.0
        imagePullPolicy: Always
        name: routing-proxy
        ports:
        - containerPort: 8000
          protocol: TCP
        resources: {}
        restartPolicy: Always
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: ms-kv-events-llm-d-modelservice
      serviceAccountName: ms-kv-events-llm-d-modelservice
      terminationGracePeriodSeconds: 30
      volumes:
      - name: model-cache
        persistentVolumeClaim:
          claimName: model-cache-pvc
      - emptyDir: {}
        name: metrics-volume
      - emptyDir: {}
        name: torch-compile-cache
      - emptyDir:
          medium: Memory
          sizeLimit: 20Gi
        name: shm
      - emptyDir:
          sizeLimit: 20Gi
        name: model-storage
